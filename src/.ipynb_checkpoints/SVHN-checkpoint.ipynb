{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def GradientReversalOperator(x):\n",
    "    def grad(dy):\n",
    "        return -1 * dy\n",
    "    return x, grad\n",
    "\n",
    "class GradientReversalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(GradientReversalLayer, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return GradientReversalOperator(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST():\n",
    "    def __init__(self, input_shape):\n",
    "        super(MNIST, self).__init__()\n",
    "        self.feature_extractor = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=5,\n",
    "                                   strides=1, input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "            tf.keras.layers.Conv2D(filters=48, kernel_size=5, strides=1),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "            tf.keras.layers.Flatten()            \n",
    "        ])\n",
    "        \n",
    "        self.label_predictor = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(100),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(100),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self.domain_predictor = tf.keras.models.Sequential([\n",
    "            GradientReversalLayer(),\n",
    "            tf.keras.layers.Dense(100),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(2),\n",
    "            tf.keras.layers.Activation('sigmoid')          \n",
    "        ])\n",
    "        self.path_1 = tf.keras.models.Sequential([\n",
    "            self.feature_extractor,\n",
    "            self.label_predictor\n",
    "        ])\n",
    "        self.path_2 = tf.keras.models.Sequential([\n",
    "            self.feature_extractor,\n",
    "            self.domain_predictor\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.loss_2 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.loss_3 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.optimizer_2 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        self.train_loss = tf.keras.metrics.Mean()\n",
    "        self.train_loss_2 = tf.keras.metrics.Mean()\n",
    "        \n",
    "        self.train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.train_accuracy_2 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "        \n",
    "        self.test_loss = tf.keras.metrics.Mean()\n",
    "        self.test_loss_2 = tf.keras.metrics.Mean()\n",
    "        self.test_loss_3 = tf.keras.metrics.Mean()\n",
    "        self.test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.test_accuracy_2 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.test_accuracy_3 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    @tf.function\n",
    "    def train_both(self, x_class, y_class, x_domain):\n",
    "        \n",
    "        domain_labels = np.concatenate([np.zeros(len(x_class)), np.ones(len(x_domain))])\n",
    "        \n",
    "        x_both = tf.concat([x_class, x_domain], axis = 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_class_pred = self.path_1(x_class)\n",
    "            loss_1 = self.loss(y_class, y_class_pred)   \n",
    "        grad_1 = tape.gradient(loss_1, self.path_1.trainable_variables)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_domain_pred = self.path_2(x_both)\n",
    "            loss_2 = self.loss_2(domain_labels, y_domain_pred) \n",
    "        grad_2 = tape.gradient(loss_2, self.path_2.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(grad_1, self.path_1.trainable_variables))\n",
    "        self.optimizer_2.apply_gradients(zip(grad_2, self.path_2.trainable_variables))\n",
    "        self.train_loss(loss_1)\n",
    "        self.train_accuracy(y_class, y_class_pred)\n",
    "        \n",
    "        self.train_loss_2(loss_2)\n",
    "        self.train_accuracy_2(domain_labels, y_domain_pred)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    @tf.function\n",
    "    def test_both(self, x_class, y_class, x_domain, y_domain):\n",
    "        \n",
    "        domain_labels = np.concatenate([np.zeros(len(x_class)), np.ones(len(x_domain))])\n",
    "        \n",
    "        x_both = tf.concat([x_class, x_domain], axis = 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_class_pred = self.path_1(x_class)\n",
    "            y_domain_pred = self.path_2(x_both)\n",
    "            y_target_class_pred = self.path_1(x_domain)\n",
    "            \n",
    "            loss_1 = self.loss(y_class, y_class_pred)\n",
    "            loss_2 = self.loss_2(domain_labels, y_domain_pred)\n",
    "            loss_3 = self.loss_3(y_domain, y_target_class_pred)\n",
    "            \n",
    "        self.test_loss(loss_1)\n",
    "        self.test_accuracy(y_class, y_class_pred)\n",
    "        \n",
    "        self.test_loss_2(loss_2)\n",
    "        self.test_accuracy_2(domain_labels, y_domain_pred)\n",
    "        \n",
    "        self.test_loss_3(loss_3)\n",
    "        self.test_accuracy_3(y_domain, y_target_class_pred)\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN():\n",
    "    def __init__(self, input_shape):\n",
    "        super(SVHN, self).__init__()\n",
    "        self.feature_extractor = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=5,\n",
    "                                   strides=1, padding='same',\n",
    "                                   input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', strides=1),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "            tf.keras.layers.Conv2D(filters=128, kernel_size=5, padding='same', strides=1),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Flatten()            \n",
    "        ])\n",
    "        \n",
    "        self.label_predictor = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(3072),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(2048),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self.domain_predictor = tf.keras.models.Sequential([\n",
    "            GradientReversalLayer(),\n",
    "            tf.keras.layers.Dense(1024),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(1024),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(2),\n",
    "            tf.keras.layers.Activation('sigmoid')          \n",
    "        ])\n",
    "        \n",
    "        self.path_1 = tf.keras.models.Sequential([\n",
    "            self.feature_extractor,\n",
    "            self.label_predictor\n",
    "        ])\n",
    "        \n",
    "        self.path_2 = tf.keras.models.Sequential([\n",
    "            self.feature_extractor,\n",
    "            self.domain_predictor\n",
    "        ])\n",
    "        \n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.loss_2 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.loss_3 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.optimizer_2 = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "        \n",
    "        self.train_loss = tf.keras.metrics.Mean()\n",
    "        self.train_loss_2 = tf.keras.metrics.Mean()\n",
    "        \n",
    "        self.train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.train_accuracy_2 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "        \n",
    "        self.test_loss = tf.keras.metrics.Mean()\n",
    "        self.test_loss_2 = tf.keras.metrics.Mean()\n",
    "        self.test_loss_3 = tf.keras.metrics.Mean()\n",
    "        self.test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.test_accuracy_2 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.test_accuracy_3 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    @tf.function\n",
    "    def train_both(self, x_class, y_class, x_domain):\n",
    "        \n",
    "        domain_labels = np.concatenate([np.zeros(len(x_class)), np.ones(len(x_domain))])\n",
    "        \n",
    "        x_both = tf.concat([x_class, x_domain], axis = 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_class_pred = self.path_1(x_class)\n",
    "            loss_1 = self.loss(y_class, y_class_pred)   \n",
    "        grad_1 = tape.gradient(loss_1, self.path_1.trainable_variables)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_domain_pred = self.path_2(x_both)\n",
    "            loss_2 = self.loss_2(domain_labels, y_domain_pred) \n",
    "        grad_2 = tape.gradient(loss_2, self.path_2.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(grad_1, self.path_1.trainable_variables))\n",
    "        self.optimizer_2.apply_gradients(zip(grad_2, self.path_2.trainable_variables))\n",
    "        self.train_loss(loss_1)\n",
    "        self.train_accuracy(y_class, y_class_pred)\n",
    "        \n",
    "        self.train_loss_2(loss_2)\n",
    "        self.train_accuracy_2(domain_labels, y_domain_pred)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    @tf.function\n",
    "    def test_both(self, x_class, y_class, x_domain, y_domain):\n",
    "        \n",
    "        domain_labels = np.concatenate([np.zeros(len(x_class)), np.ones(len(x_domain))])\n",
    "        \n",
    "        x_both = tf.concat([x_class, x_domain], axis = 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_class_pred = self.path_1(x_class)\n",
    "            y_domain_pred = self.path_2(x_both)\n",
    "            y_target_class_pred = self.path_1(x_domain)\n",
    "            \n",
    "            loss_1 = self.loss(y_class, y_class_pred)\n",
    "            loss_2 = self.loss_2(domain_labels, y_domain_pred)\n",
    "            loss_3 = self.loss_3(y_domain, y_target_class_pred)\n",
    "            \n",
    "        self.test_loss(loss_1)\n",
    "        self.test_accuracy(y_class, y_class_pred)\n",
    "        \n",
    "        self.test_loss_2(loss_2)\n",
    "        self.test_accuracy_2(domain_labels, y_domain_pred)\n",
    "        \n",
    "        self.test_loss_3(loss_3)\n",
    "        self.test_accuracy_3(y_domain, y_target_class_pred)\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist = np.load('../data/mnist/x_train.npy')\n",
    "y_train_mnist = np.load('../data/mnist/y_train.npy')\n",
    "\n",
    "x_test_mnist = np.load('../data/mnist/x_test.npy')\n",
    "y_test_mnist = np.load('../data/mnist/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_svhn = np.load('../data/svhn/x_train.npy')\n",
    "y_train_svhn = np.load('../data/svhn/y_train.npy')\n",
    "\n",
    "x_test_svhn = np.load('../data/svhn/x_test.npy')\n",
    "y_test_svhn = np.load('../data/svhn/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
    "x_train_svhn, x_test_svhn = x_train_svhn / 255.0, x_test_svhn / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist = tf.cast(x_train_mnist, tf.float32)\n",
    "x_test_mnist = tf.cast(x_test_mnist, tf.float32)\n",
    "x_train_svhn = tf.cast(x_train_svhn, tf.float32)\n",
    "x_test_svhn = tf.cast(x_test_svhn, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(x, y):\n",
    "    \n",
    "    paddings = tf.constant([[2, 2,], [2, 2]])\n",
    "    \n",
    "    new_x = tf.pad(x, paddings, \"CONSTANT\")\n",
    "    \n",
    "    return (new_x, y)\n",
    "\n",
    "def duplicate_channel(x, y):\n",
    "\n",
    "    new_x = tf.stack([x, x, x], axis = -1)\n",
    "    \n",
    "    return (new_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([73257, 32, 32, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_svhn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = tf.data.Dataset.from_tensor_slices((x_train_mnist, y_train_mnist))\n",
    "mnist_train_dataset = mnist_train_dataset.map(pad_image)\n",
    "mnist_train_dataset = mnist_train_dataset.map(duplicate_channel)\n",
    "target_train_dataset = mnist_train_dataset.shuffle(len(y_train_mnist))\n",
    "\n",
    "mnist_test_dataset = tf.data.Dataset.from_tensor_slices((x_test_mnist, y_test_mnist))\n",
    "mnist_test_dataset = mnist_test_dataset.map(pad_image)\n",
    "mnist_test_dataset = mnist_test_dataset.map(duplicate_channel)\n",
    "target_test_dataset = mnist_test_dataset.shuffle(len(y_test_mnist))\n",
    "\n",
    "svhn_train_dataset = tf.data.Dataset.from_tensor_slices((x_train_svhn, y_train_svhn))\n",
    "source_train_dataset = svhn_train_dataset.shuffle(len(y_train_svhn))\n",
    "\n",
    "svhn_test_dataset = tf.data.Dataset.from_tensor_slices((x_test_svhn, y_test_svhn))\n",
    "source_test_dataset = svhn_train_dataset.shuffle(len(y_test_svhn))\n",
    "\n",
    "\n",
    "\n",
    "source_train_dataset = source_train_dataset.batch(600)\n",
    "source_train_dataset = source_train_dataset.prefetch(50)\n",
    "\n",
    "target_train_dataset = target_train_dataset.batch(730)\n",
    "target_train_dataset = target_train_dataset.prefetch(50)\n",
    "\n",
    "source_test_dataset = source_test_dataset.batch(100)\n",
    "source_test_dataset = source_test_dataset.prefetch(50)\n",
    "\n",
    "# target_test_dataset = target_test_dataset.batch(500)\n",
    "# target_test_dataset = target_test_dataset.prefetch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SVHN(input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0627 19:21:48.579602 11780 deprecation.py:323] From c:\\users\\jw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "L1: 2.2517, Acc1: 19.61, L1 Test: 1.9080, Acc1 Test: 30.87\n",
      "L2: 0.6280, Acc2: 70.62, L2 Test: 0.7181, Acc2 Test: 54.99\n",
      "L3 Test: 2.0642, Acc3 Test: 22.20\n",
      "\n",
      "Epoch: 2\n",
      "L1: 1.6619, Acc1: 42.32, L1 Test: 1.2618, Acc1 Test: 55.62\n",
      "L2: 0.4935, Acc2: 78.23, L2 Test: 0.5862, Acc2 Test: 69.74\n",
      "L3 Test: 2.0241, Acc3 Test: 40.62\n",
      "\n",
      "Epoch: 3\n",
      "L1: 1.2745, Acc1: 56.33, L1 Test: 0.9733, Acc1 Test: 66.35\n",
      "L2: 0.4567, Acc2: 80.02, L2 Test: 0.4078, Acc2 Test: 79.45\n",
      "L3 Test: 1.9035, Acc3 Test: 47.06\n",
      "\n",
      "Epoch: 4\n",
      "L1: 1.0507, Acc1: 64.30, L1 Test: 0.8178, Acc1 Test: 72.15\n",
      "L2: 0.3494, Acc2: 84.84, L2 Test: 0.3280, Acc2 Test: 83.80\n",
      "L3 Test: 1.9321, Acc3 Test: 49.59\n",
      "\n",
      "Epoch: 5\n",
      "L1: 0.9043, Acc1: 69.51, L1 Test: 0.7124, Acc1 Test: 76.00\n",
      "L2: 0.2825, Acc2: 87.79, L2 Test: 0.2631, Acc2 Test: 87.03\n",
      "L3 Test: 1.9010, Acc3 Test: 52.28\n",
      "\n",
      "Epoch: 6\n",
      "L1: 0.7999, Acc1: 73.19, L1 Test: 0.6379, Acc1 Test: 78.68\n",
      "L2: 0.2396, Acc2: 89.69, L2 Test: 0.2755, Acc2 Test: 87.62\n",
      "L3 Test: 1.9005, Acc3 Test: 54.69\n",
      "\n",
      "Epoch: 7\n",
      "L1: 0.7223, Acc1: 75.91, L1 Test: 0.5828, Acc1 Test: 80.62\n",
      "L2: 0.2649, Acc2: 89.14, L2 Test: 0.2667, Acc2 Test: 88.86\n",
      "L3 Test: 2.0307, Acc3 Test: 55.21\n",
      "\n",
      "Epoch: 8\n",
      "L1: 0.6585, Acc1: 78.12, L1 Test: 0.5358, Acc1 Test: 82.28\n",
      "L2: 0.2373, Acc2: 90.36, L2 Test: 0.2368, Acc2 Test: 90.15\n",
      "L3 Test: 2.1316, Acc3 Test: 56.12\n",
      "\n",
      "Epoch: 9\n",
      "L1: 0.6050, Acc1: 79.96, L1 Test: 0.4982, Acc1 Test: 83.59\n",
      "L2: 0.2128, Acc2: 91.38, L2 Test: 0.2113, Acc2 Test: 91.23\n",
      "L3 Test: 2.1952, Acc3 Test: 56.88\n",
      "\n",
      "Epoch: 10\n",
      "L1: 0.5606, Acc1: 81.47, L1 Test: 0.4665, Acc1 Test: 84.70\n",
      "L2: 0.1922, Acc2: 92.23, L2 Test: 0.1911, Acc2 Test: 92.08\n",
      "L3 Test: 2.2707, Acc3 Test: 57.51\n",
      "\n",
      "Epoch: 11\n",
      "L1: 0.5222, Acc1: 82.77, L1 Test: 0.4398, Acc1 Test: 85.63\n",
      "L2: 0.1756, Acc2: 92.90, L2 Test: 0.1739, Acc2 Test: 92.79\n",
      "L3 Test: 2.3215, Acc3 Test: 58.21\n",
      "\n",
      "Epoch: 12\n",
      "L1: 0.4886, Acc1: 83.90, L1 Test: 0.4166, Acc1 Test: 86.46\n",
      "L2: 0.1612, Acc2: 93.49, L2 Test: 0.1595, Acc2 Test: 93.39\n",
      "L3 Test: 2.5442, Acc3 Test: 58.32\n",
      "\n",
      "Epoch: 13\n",
      "L1: 0.4588, Acc1: 84.89, L1 Test: 0.4008, Acc1 Test: 87.06\n",
      "L2: 0.1489, Acc2: 93.99, L2 Test: 0.1473, Acc2 Test: 93.90\n",
      "L3 Test: 2.7549, Acc3 Test: 58.37\n",
      "\n",
      "Epoch: 14\n",
      "L1: 0.4321, Acc1: 85.77, L1 Test: 0.3832, Acc1 Test: 87.71\n",
      "L2: 0.1384, Acc2: 94.41, L2 Test: 0.1370, Acc2 Test: 94.33\n",
      "L3 Test: 2.9883, Acc3 Test: 58.46\n",
      "\n",
      "Epoch: 15\n",
      "L1: 0.4086, Acc1: 86.56, L1 Test: 0.3674, Acc1 Test: 88.30\n",
      "L2: 0.1293, Acc2: 94.78, L2 Test: 0.1279, Acc2 Test: 94.70\n",
      "L3 Test: 3.2155, Acc3 Test: 58.64\n",
      "\n",
      "Epoch: 16\n",
      "L1: 0.3875, Acc1: 87.25, L1 Test: 0.3540, Acc1 Test: 88.81\n",
      "L2: 0.1213, Acc2: 95.11, L2 Test: 0.1200, Acc2 Test: 95.03\n",
      "L3 Test: 3.4521, Acc3 Test: 58.64\n",
      "\n",
      "Epoch: 17\n",
      "L1: 0.3684, Acc1: 87.88, L1 Test: 0.3417, Acc1 Test: 89.26\n",
      "L2: 0.1142, Acc2: 95.39, L2 Test: 0.1130, Acc2 Test: 95.32\n",
      "L3 Test: 3.6839, Acc3 Test: 58.62\n",
      "\n",
      "Epoch: 18\n",
      "L1: 0.3507, Acc1: 88.46, L1 Test: 0.3333, Acc1 Test: 89.62\n",
      "L2: 0.1079, Acc2: 95.65, L2 Test: 0.1067, Acc2 Test: 95.58\n",
      "L3 Test: 3.9991, Acc3 Test: 58.58\n",
      "\n",
      "Epoch: 19\n",
      "L1: 0.3341, Acc1: 89.01, L1 Test: 0.3238, Acc1 Test: 89.99\n",
      "L2: 0.1022, Acc2: 95.88, L2 Test: 0.1011, Acc2 Test: 95.81\n",
      "L3 Test: 4.2544, Acc3 Test: 58.64\n",
      "\n",
      "Epoch: 20\n",
      "L1: 0.3192, Acc1: 89.50, L1 Test: 0.3151, Acc1 Test: 90.34\n",
      "L2: 0.0972, Acc2: 96.08, L2 Test: 0.0961, Acc2 Test: 96.02\n",
      "L3 Test: 4.4446, Acc3 Test: 58.85\n",
      "\n",
      "Epoch: 21\n",
      "L1: 0.3054, Acc1: 89.95, L1 Test: 0.3077, Acc1 Test: 90.64\n",
      "L2: 0.0926, Acc2: 96.27, L2 Test: 0.0916, Acc2 Test: 96.21\n",
      "L3 Test: 4.6710, Acc3 Test: 58.93\n",
      "\n",
      "Epoch: 22\n",
      "L1: 0.2928, Acc1: 90.37, L1 Test: 0.3016, Acc1 Test: 90.92\n",
      "L2: 0.0884, Acc2: 96.44, L2 Test: 0.0875, Acc2 Test: 96.38\n",
      "L3 Test: 5.0498, Acc3 Test: 58.78\n",
      "\n",
      "Epoch: 23\n",
      "L1: 0.2812, Acc1: 90.75, L1 Test: 0.2959, Acc1 Test: 91.19\n",
      "L2: 0.0847, Acc2: 96.59, L2 Test: 0.0838, Acc2 Test: 96.53\n",
      "L3 Test: 5.2525, Acc3 Test: 58.82\n",
      "\n",
      "Epoch: 24\n",
      "L1: 0.2706, Acc1: 91.10, L1 Test: 0.2899, Acc1 Test: 91.46\n",
      "L2: 0.0812, Acc2: 96.73, L2 Test: 0.0803, Acc2 Test: 96.68\n",
      "L3 Test: 5.4649, Acc3 Test: 58.85\n",
      "\n",
      "Epoch: 25\n",
      "L1: 0.2608, Acc1: 91.43, L1 Test: 0.2848, Acc1 Test: 91.69\n",
      "L2: 0.0779, Acc2: 96.86, L2 Test: 0.0771, Acc2 Test: 96.81\n",
      "L3 Test: 5.6591, Acc3 Test: 58.82\n",
      "\n",
      "Epoch: 26\n",
      "L1: 0.2516, Acc1: 91.73, L1 Test: 0.2793, Acc1 Test: 91.92\n",
      "L2: 0.0749, Acc2: 96.98, L2 Test: 0.0742, Acc2 Test: 96.93\n",
      "L3 Test: 5.8235, Acc3 Test: 58.94\n",
      "\n",
      "Epoch: 27\n",
      "L1: 0.2429, Acc1: 92.02, L1 Test: 0.2748, Acc1 Test: 92.14\n",
      "L2: 0.0722, Acc2: 97.09, L2 Test: 0.0714, Acc2 Test: 97.05\n",
      "L3 Test: 6.0562, Acc3 Test: 59.05\n",
      "\n",
      "Epoch: 28\n",
      "L1: 0.2350, Acc1: 92.28, L1 Test: 0.2704, Acc1 Test: 92.34\n",
      "L2: 0.0696, Acc2: 97.19, L2 Test: 0.0689, Acc2 Test: 97.15\n",
      "L3 Test: 6.3063, Acc3 Test: 59.09\n",
      "\n",
      "Epoch: 29\n",
      "L1: 0.2275, Acc1: 92.53, L1 Test: 0.2666, Acc1 Test: 92.53\n",
      "L2: 0.0672, Acc2: 97.29, L2 Test: 0.0665, Acc2 Test: 97.25\n",
      "L3 Test: 6.5319, Acc3 Test: 59.16\n",
      "\n",
      "Epoch: 30\n",
      "L1: 0.2205, Acc1: 92.76, L1 Test: 0.2631, Acc1 Test: 92.70\n",
      "L2: 0.0650, Acc2: 97.38, L2 Test: 0.0643, Acc2 Test: 97.34\n",
      "L3 Test: 6.6856, Acc3 Test: 59.19\n",
      "\n",
      "Epoch: 31\n",
      "L1: 0.2139, Acc1: 92.98, L1 Test: 0.2598, Acc1 Test: 92.86\n",
      "L2: 0.0629, Acc2: 97.47, L2 Test: 0.0622, Acc2 Test: 97.43\n",
      "L3 Test: 6.8113, Acc3 Test: 59.27\n",
      "\n",
      "Epoch: 32\n",
      "L1: 0.2077, Acc1: 93.18, L1 Test: 0.2564, Acc1 Test: 93.01\n",
      "L2: 0.0609, Acc2: 97.54, L2 Test: 0.0603, Acc2 Test: 97.51\n",
      "L3 Test: 6.9665, Acc3 Test: 59.29\n",
      "\n",
      "Epoch: 33\n",
      "L1: 0.2019, Acc1: 93.37, L1 Test: 0.2536, Acc1 Test: 93.16\n",
      "L2: 0.0591, Acc2: 97.62, L2 Test: 0.0585, Acc2 Test: 97.58\n",
      "L3 Test: 7.1225, Acc3 Test: 59.36\n",
      "\n",
      "Epoch: 34\n",
      "L1: 0.1965, Acc1: 93.55, L1 Test: 0.2515, Acc1 Test: 93.29\n",
      "L2: 0.0573, Acc2: 97.69, L2 Test: 0.0568, Acc2 Test: 97.65\n",
      "L3 Test: 7.3871, Acc3 Test: 59.29\n",
      "\n",
      "Epoch: 35\n",
      "L1: 0.1915, Acc1: 93.72, L1 Test: 0.2490, Acc1 Test: 93.41\n",
      "L2: 0.0557, Acc2: 97.76, L2 Test: 0.0551, Acc2 Test: 97.72\n",
      "L3 Test: 7.5718, Acc3 Test: 59.26\n",
      "\n",
      "Epoch: 36\n",
      "L1: 0.1867, Acc1: 93.88, L1 Test: 0.2465, Acc1 Test: 93.53\n",
      "L2: 0.0541, Acc2: 97.82, L2 Test: 0.0536, Acc2 Test: 97.78\n",
      "L3 Test: 7.6635, Acc3 Test: 59.36\n",
      "\n",
      "Epoch: 37\n",
      "L1: 0.1821, Acc1: 94.03, L1 Test: 0.2443, Acc1 Test: 93.65\n",
      "L2: 0.0527, Acc2: 97.88, L2 Test: 0.0522, Acc2 Test: 97.84\n",
      "L3 Test: 7.7474, Acc3 Test: 59.47\n",
      "\n",
      "Epoch: 38\n",
      "L1: 0.1777, Acc1: 94.18, L1 Test: 0.2424, Acc1 Test: 93.76\n",
      "L2: 0.0513, Acc2: 97.93, L2 Test: 0.0508, Acc2 Test: 97.90\n",
      "L3 Test: 7.8738, Acc3 Test: 59.56\n",
      "\n",
      "Epoch: 39\n",
      "L1: 0.1735, Acc1: 94.31, L1 Test: 0.2402, Acc1 Test: 93.86\n",
      "L2: 0.0500, Acc2: 97.99, L2 Test: 0.0495, Acc2 Test: 97.95\n",
      "L3 Test: 8.0190, Acc3 Test: 59.57\n",
      "\n",
      "Epoch: 40\n",
      "L1: 0.1694, Acc1: 94.45, L1 Test: 0.2385, Acc1 Test: 93.96\n",
      "L2: 0.0487, Acc2: 98.04, L2 Test: 0.0483, Acc2 Test: 98.00\n",
      "L3 Test: 8.1162, Acc3 Test: 59.65\n",
      "\n",
      "Epoch: 41\n",
      "L1: 0.1657, Acc1: 94.57, L1 Test: 0.2369, Acc1 Test: 94.05\n",
      "L2: 0.0476, Acc2: 98.08, L2 Test: 0.0471, Acc2 Test: 98.05\n",
      "L3 Test: 8.2774, Acc3 Test: 59.68\n",
      "\n",
      "Epoch: 42\n",
      "L1: 0.1622, Acc1: 94.69, L1 Test: 0.2359, Acc1 Test: 94.14\n",
      "L2: 0.0464, Acc2: 98.13, L2 Test: 0.0460, Acc2 Test: 98.10\n",
      "L3 Test: 8.5010, Acc3 Test: 59.67\n",
      "\n",
      "Epoch: 43\n",
      "L1: 0.1588, Acc1: 94.80, L1 Test: 0.2341, Acc1 Test: 94.23\n",
      "L2: 0.0453, Acc2: 98.17, L2 Test: 0.0449, Acc2 Test: 98.14\n",
      "L3 Test: 8.7737, Acc3 Test: 59.65\n",
      "\n",
      "Epoch: 44\n",
      "L1: 0.1555, Acc1: 94.91, L1 Test: 0.2324, Acc1 Test: 94.32\n",
      "L2: 0.0443, Acc2: 98.21, L2 Test: 0.0439, Acc2 Test: 98.18\n",
      "L3 Test: 8.9785, Acc3 Test: 59.62\n",
      "\n",
      "Epoch: 45\n",
      "L1: 0.1524, Acc1: 95.01, L1 Test: 0.2307, Acc1 Test: 94.40\n",
      "L2: 0.0433, Acc2: 98.25, L2 Test: 0.0430, Acc2 Test: 98.22\n",
      "L3 Test: 9.0493, Acc3 Test: 59.70\n",
      "\n",
      "Epoch: 46\n",
      "L1: 0.1493, Acc1: 95.11, L1 Test: 0.2293, Acc1 Test: 94.48\n",
      "L2: 0.0424, Acc2: 98.29, L2 Test: 0.0420, Acc2 Test: 98.26\n",
      "L3 Test: 9.1641, Acc3 Test: 59.74\n",
      "\n",
      "Epoch: 47\n",
      "L1: 0.1464, Acc1: 95.21, L1 Test: 0.2282, Acc1 Test: 94.55\n",
      "L2: 0.0415, Acc2: 98.33, L2 Test: 0.0411, Acc2 Test: 98.30\n",
      "L3 Test: 9.2748, Acc3 Test: 59.73\n",
      "\n",
      "Epoch: 48\n",
      "L1: 0.1435, Acc1: 95.30, L1 Test: 0.2269, Acc1 Test: 94.63\n",
      "L2: 0.0406, Acc2: 98.36, L2 Test: 0.0403, Acc2 Test: 98.34\n",
      "L3 Test: 9.3977, Acc3 Test: 59.77\n",
      "\n",
      "Epoch: 49\n",
      "L1: 0.1408, Acc1: 95.39, L1 Test: 0.2261, Acc1 Test: 94.69\n",
      "L2: 0.0398, Acc2: 98.40, L2 Test: 0.0395, Acc2 Test: 98.37\n",
      "L3 Test: 9.5345, Acc3 Test: 59.79\n",
      "\n",
      "Epoch: 50\n",
      "L1: 0.1384, Acc1: 95.47, L1 Test: 0.2250, Acc1 Test: 94.75\n",
      "L2: 0.0390, Acc2: 98.43, L2 Test: 0.0387, Acc2 Test: 98.40\n",
      "L3 Test: 9.6008, Acc3 Test: 59.83\n",
      "\n",
      "Epoch: 51\n",
      "L1: 0.1359, Acc1: 95.55, L1 Test: 0.2238, Acc1 Test: 94.81\n",
      "L2: 0.0383, Acc2: 98.46, L2 Test: 0.0380, Acc2 Test: 98.43\n",
      "L3 Test: 9.6740, Acc3 Test: 59.92\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52\n",
      "L1: 0.1336, Acc1: 95.63, L1 Test: 0.2226, Acc1 Test: 94.88\n",
      "L2: 0.0375, Acc2: 98.49, L2 Test: 0.0372, Acc2 Test: 98.46\n",
      "L3 Test: 9.7329, Acc3 Test: 59.98\n",
      "\n",
      "Epoch: 53\n",
      "L1: 0.1312, Acc1: 95.71, L1 Test: 0.2220, Acc1 Test: 94.93\n",
      "L2: 0.0368, Acc2: 98.52, L2 Test: 0.0366, Acc2 Test: 98.49\n",
      "L3 Test: 9.8088, Acc3 Test: 60.04\n",
      "\n",
      "Epoch: 54\n",
      "L1: 0.1290, Acc1: 95.78, L1 Test: 0.2208, Acc1 Test: 94.99\n",
      "L2: 0.0364, Acc2: 98.53, L2 Test: 0.0359, Acc2 Test: 98.52\n",
      "L3 Test: 9.9375, Acc3 Test: 59.94\n",
      "\n",
      "Epoch: 55\n",
      "L1: 0.1270, Acc1: 95.85, L1 Test: 0.2198, Acc1 Test: 95.04\n",
      "L2: 0.0358, Acc2: 98.56, L2 Test: 0.0354, Acc2 Test: 98.54\n",
      "L3 Test: 10.0345, Acc3 Test: 59.93\n",
      "\n",
      "Epoch: 56\n",
      "L1: 0.1250, Acc1: 95.92, L1 Test: 0.2188, Acc1 Test: 95.10\n",
      "L2: 0.0352, Acc2: 98.58, L2 Test: 0.0348, Acc2 Test: 98.56\n",
      "L3 Test: 10.1465, Acc3 Test: 59.92\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-204b3068c8da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msource_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtarget_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_train_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_both\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtarget_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_test_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    402\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    587\u001b[0m     \"\"\"\n\u001b[0;32m    588\u001b[0m     return self._call_flat(\n\u001b[1;32m--> 589\u001b[1;33m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[0;32m    590\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m    591\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[1;32mc:\\users\\jw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 445\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    446\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (source_images, class_labels), (target_images, _) in zip(source_train_dataset, target_train_dataset):\n",
    "        model.train_both(source_images, class_labels, target_images)\n",
    "\n",
    "    for (test_images, test_labels), (target_images, target_labels) in zip(source_test_dataset, target_train_dataset):\n",
    "        model.test_both(test_images, test_labels, target_images, target_labels)\n",
    "\n",
    "    template = 'Epoch: {}\\n' + \\\n",
    "    'L1: {:.4f}, Acc1: {:.2f}, L1 Test: {:.4f}, Acc1 Test: {:.2f}\\n'+ \\\n",
    "    'L2: {:.4f}, Acc2: {:.2f}, L2 Test: {:.4f}, Acc2 Test: {:.2f}\\n'+ \\\n",
    "    'L3 Test: {:.4f}, Acc3 Test: {:.2f}\\n'\n",
    "    \n",
    "    \n",
    "    print(template.format(epoch+1,\n",
    "                         model.train_loss.result(),\n",
    "                         model.train_accuracy.result()*100,\n",
    "                         model.test_loss.result(),\n",
    "                         model.test_accuracy.result()*100,\n",
    "                         model.train_loss_2.result(),\n",
    "                         model.train_accuracy_2.result()*100,\n",
    "                         model.test_loss_2.result(),\n",
    "                         model.test_accuracy_2.result()*100,\n",
    "                         model.test_loss_3.result(),\n",
    "                         model.test_accuracy_3.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
