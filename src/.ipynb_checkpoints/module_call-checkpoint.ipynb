{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DANN_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist = np.load('../data/mnist/x_train.npy')\n",
    "y_train_mnist = np.load('../data/mnist/y_train.npy')\n",
    "\n",
    "x_test_mnist = np.load('../data/mnist/x_test.npy')\n",
    "y_test_mnist = np.load('../data/mnist/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_svhn = np.load('../data/svhn/x_train.npy')\n",
    "y_train_svhn = np.load('../data/svhn/y_train.npy')\n",
    "\n",
    "x_test_svhn = np.load('../data/svhn/x_test.npy')\n",
    "y_test_svhn = np.load('../data/svhn/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
    "x_train_svhn, x_test_svhn = x_train_svhn / 255.0, x_test_svhn / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist = tf.cast(x_train_mnist, tf.float32)\n",
    "x_test_mnist = tf.cast(x_test_mnist, tf.float32)\n",
    "x_train_svhn = tf.cast(x_train_svhn, tf.float32)\n",
    "x_test_svhn = tf.cast(x_test_svhn, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(x, y):\n",
    "    \n",
    "    paddings = tf.constant([[2, 2,], [2, 2]])\n",
    "    \n",
    "    new_x = tf.pad(x, paddings, \"CONSTANT\")\n",
    "    \n",
    "    return (new_x, y)\n",
    "\n",
    "def duplicate_channel(x, y):\n",
    "\n",
    "    new_x = tf.stack([x, x, x], axis = -1)\n",
    "    \n",
    "    return (new_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = tf.data.Dataset.from_tensor_slices((x_train_mnist, y_train_mnist))\n",
    "mnist_train_dataset = mnist_train_dataset.map(pad_image)\n",
    "mnist_train_dataset = mnist_train_dataset.map(duplicate_channel)\n",
    "target_train_dataset = mnist_train_dataset.shuffle(len(y_train_mnist))\n",
    "\n",
    "mnist_test_dataset = tf.data.Dataset.from_tensor_slices((x_test_mnist, y_test_mnist))\n",
    "mnist_test_dataset = mnist_test_dataset.map(pad_image)\n",
    "mnist_test_dataset = mnist_test_dataset.map(duplicate_channel)\n",
    "target_test_dataset = mnist_test_dataset.shuffle(len(y_test_mnist))\n",
    "\n",
    "svhn_train_dataset = tf.data.Dataset.from_tensor_slices((x_train_svhn, y_train_svhn))\n",
    "source_train_dataset = svhn_train_dataset.shuffle(len(y_train_svhn))\n",
    "\n",
    "svhn_test_dataset = tf.data.Dataset.from_tensor_slices((x_test_svhn, y_test_svhn))\n",
    "source_test_dataset = svhn_train_dataset.shuffle(len(y_test_svhn))\n",
    "\n",
    "\n",
    "\n",
    "source_train_dataset = source_train_dataset.batch(730)\n",
    "source_train_dataset = source_train_dataset.prefetch(50)\n",
    "\n",
    "source_test_dataset = source_test_dataset.batch(260)\n",
    "source_test_dataset = source_test_dataset.prefetch(50)\n",
    "\n",
    "target_train_dataset = target_train_dataset.batch(600)\n",
    "target_train_dataset = target_train_dataset.prefetch(50)\n",
    "\n",
    "# target_test_dataset = target_test_dataset.batch(500)\n",
    "# target_test_dataset = target_test_dataset.prefetch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = DANN_Model(input_shape=(32, 32, 3), model_type='SVHN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0628 00:27:09.289459  8024 deprecation.py:323] From c:\\users\\jw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "L1: 2.2218, Acc1: 20.65, L1 Test: 1.9498, Acc1 Test: 30.60\n",
      "L2: 0.6633, Acc2: 65.01, L2 Test: 0.3951, Acc2 Test: 76.44\n",
      "L3 Test: 2.3967, Acc3 Test: 22.54\n",
      "\n",
      "Epoch: 2\n",
      "L1: 1.1559, Acc1: 61.29, L1 Test: 0.6873, Acc1 Test: 78.43\n",
      "L2: 0.4426, Acc2: 80.37, L2 Test: 0.3512, Acc2 Test: 86.26\n",
      "L3 Test: 2.3579, Acc3 Test: 39.02\n",
      "\n",
      "Epoch: 3\n",
      "L1: 0.5635, Acc1: 82.49, L1 Test: 0.4554, Acc1 Test: 86.02\n",
      "L2: 0.4572, Acc2: 79.82, L2 Test: 0.1633, Acc2 Test: 96.27\n",
      "L3 Test: 2.7416, Acc3 Test: 50.95\n",
      "\n",
      "Epoch: 4\n",
      "L1: 0.4179, Acc1: 87.03, L1 Test: 0.3640, Acc1 Test: 88.85\n",
      "L2: 0.0615, Acc2: 99.32, L2 Test: 0.0259, Acc2 Test: 99.64\n",
      "L3 Test: 2.1104, Acc3 Test: 51.19\n",
      "\n",
      "Epoch: 5\n",
      "L1: 0.3587, Acc1: 89.03, L1 Test: 0.3366, Acc1 Test: 89.65\n",
      "L2: 0.1260, Acc2: 95.38, L2 Test: 0.2498, Acc2 Test: 89.92\n",
      "L3 Test: 2.2540, Acc3 Test: 50.18\n",
      "\n",
      "Epoch: 6\n",
      "L1: 0.3347, Acc1: 89.66, L1 Test: 0.2829, Acc1 Test: 91.55\n",
      "L2: 1.1666, Acc2: 70.58, L2 Test: 0.1869, Acc2 Test: 99.82\n",
      "L3 Test: 2.7750, Acc3 Test: 48.82\n",
      "\n",
      "Epoch: 7\n",
      "L1: 0.2772, Acc1: 91.59, L1 Test: 0.2633, Acc1 Test: 92.03\n",
      "L2: 0.0339, Acc2: 99.89, L2 Test: 0.0038, Acc2 Test: 99.98\n",
      "L3 Test: 2.0447, Acc3 Test: 52.28\n",
      "\n",
      "Epoch: 8\n",
      "L1: 0.2514, Acc1: 92.39, L1 Test: 0.2400, Acc1 Test: 92.84\n",
      "L2: 0.0065, Acc2: 99.91, L2 Test: 0.0030, Acc2 Test: 99.98\n",
      "L3 Test: 2.0618, Acc3 Test: 50.62\n",
      "\n",
      "Epoch: 9\n",
      "L1: 0.2244, Acc1: 93.29, L1 Test: 0.2243, Acc1 Test: 93.23\n",
      "L2: 0.0024, Acc2: 99.97, L2 Test: 0.0020, Acc2 Test: 99.98\n",
      "L3 Test: 2.2551, Acc3 Test: 55.14\n",
      "\n",
      "Epoch: 10\n",
      "L1: 0.2091, Acc1: 93.74, L1 Test: 0.2072, Acc1 Test: 93.57\n",
      "L2: 0.0029, Acc2: 99.95, L2 Test: 0.0035, Acc2 Test: 99.94\n",
      "L3 Test: 2.3158, Acc3 Test: 55.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (source_images, class_labels), (target_images, _) in zip(source_train_dataset, target_train_dataset):\n",
    "        model.train(source_images, class_labels, target_images)\n",
    "\n",
    "    for (test_images, test_labels), (target_images, target_labels) in zip(source_test_dataset, target_train_dataset):\n",
    "        model.test(test_images, test_labels, target_images, target_labels)\n",
    "    \n",
    "    print('Epoch: {}'.format(epoch + 1))\n",
    "    print(model.log())\n",
    "    model.reset_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
