{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def GradientReversalOperator(x):\n",
    "    def grad(dy):\n",
    "        return -1 * dy\n",
    "    return x, grad\n",
    "\n",
    "class GradientReversalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(GradientReversalLayer, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return GradientReversalOperator(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST():\n",
    "    def __init__(self, input_shape):\n",
    "        super(MNIST, self).__init__()\n",
    "        self.feature_extractor = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=5,\n",
    "                                   strides=1, input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "            tf.keras.layers.Conv2D(filters=48, kernel_size=5, strides=1),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "            tf.keras.layers.Flatten()            \n",
    "        ])\n",
    "        \n",
    "        self.label_predictor = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(100),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(100),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self.domain_predictor = tf.keras.models.Sequential([\n",
    "            GradientReversalLayer(),\n",
    "            tf.keras.layers.Dense(100),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(2),\n",
    "            tf.keras.layers.Activation('sigmoid')          \n",
    "        ])\n",
    "        self.path_1 = tf.keras.models.Sequential([\n",
    "            self.feature_extractor,\n",
    "            self.label_predictor\n",
    "        ])\n",
    "        self.path_2 = tf.keras.models.Sequential([\n",
    "            self.feature_extractor,\n",
    "            self.domain_predictor\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.loss_2 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.loss_3 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.optimizer_2 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        self.train_loss = tf.keras.metrics.Mean()\n",
    "        self.train_loss_2 = tf.keras.metrics.Mean()\n",
    "        \n",
    "        self.train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.train_accuracy_2 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "        \n",
    "        self.test_loss = tf.keras.metrics.Mean()\n",
    "        self.test_loss_2 = tf.keras.metrics.Mean()\n",
    "        self.test_loss_3 = tf.keras.metrics.Mean()\n",
    "        self.test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.test_accuracy_2 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.test_accuracy_3 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    @tf.function\n",
    "    def train_both(self, x_class, y_class, x_domain):\n",
    "        \n",
    "        domain_labels = np.concatenate([np.zeros(len(x_class)), np.ones(len(x_domain))])\n",
    "        \n",
    "        x_both = tf.concat([x_class, x_domain], axis = 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_class_pred = self.path_1(x_class)\n",
    "            loss_1 = self.loss(y_class, y_class_pred)   \n",
    "        grad_1 = tape.gradient(loss_1, self.path_1.trainable_variables)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_domain_pred = self.path_2(x_both)\n",
    "            loss_2 = self.loss_2(domain_labels, y_domain_pred) \n",
    "        grad_2 = tape.gradient(loss_2, self.path_2.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(grad_1, self.path_1.trainable_variables))\n",
    "        self.optimizer_2.apply_gradients(zip(grad_2, self.path_2.trainable_variables))\n",
    "        self.train_loss(loss_1)\n",
    "        self.train_accuracy(y_class, y_class_pred)\n",
    "        \n",
    "        self.train_loss_2(loss_2)\n",
    "        self.train_accuracy_2(domain_labels, y_domain_pred)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    @tf.function\n",
    "    def test_both(self, x_class, y_class, x_domain, y_domain):\n",
    "        \n",
    "        domain_labels = np.concatenate([np.zeros(len(x_class)), np.ones(len(x_domain))])\n",
    "        \n",
    "        x_both = tf.concat([x_class, x_domain], axis = 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_class_pred = self.path_1(x_class)\n",
    "            y_domain_pred = self.path_2(x_both)\n",
    "            y_target_class_pred = self.path_1(x_domain)\n",
    "            \n",
    "            loss_1 = self.loss(y_class, y_class_pred)\n",
    "            loss_2 = self.loss_2(domain_labels, y_domain_pred)\n",
    "            loss_3 = self.loss_3(y_domain, y_target_class_pred)\n",
    "            \n",
    "        self.test_loss(loss_1)\n",
    "        self.test_accuracy(y_class, y_class_pred)\n",
    "        \n",
    "        self.test_loss_2(loss_2)\n",
    "        self.test_accuracy_2(domain_labels, y_domain_pred)\n",
    "        \n",
    "        self.test_loss_3(loss_3)\n",
    "        self.test_accuracy_3(y_domain, y_target_class_pred)\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN():\n",
    "    def __init__(self, input_shape):\n",
    "        super(SVHN, self).__init__()\n",
    "        self.feature_extractor = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=5,\n",
    "                                   strides=1, padding='same',\n",
    "                                   input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', strides=1),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "            tf.keras.layers.Conv2D(filters=128, kernel_size=5, padding='same', strides=1),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Flatten()            \n",
    "        ])\n",
    "        \n",
    "        self.label_predictor = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(3072),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(2048),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self.domain_predictor = tf.keras.models.Sequential([\n",
    "            GradientReversalLayer(),\n",
    "            tf.keras.layers.Dense(1024),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(1024),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(2),\n",
    "            tf.keras.layers.Activation('sigmoid')          \n",
    "        ])\n",
    "        \n",
    "        self.path_1 = tf.keras.models.Sequential([\n",
    "            self.feature_extractor,\n",
    "            self.label_predictor\n",
    "        ])\n",
    "        \n",
    "        self.path_2 = tf.keras.models.Sequential([\n",
    "            self.feature_extractor,\n",
    "            self.domain_predictor\n",
    "        ])\n",
    "        \n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.loss_2 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.loss_3 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.optimizer_2 = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "        \n",
    "        self.train_loss = tf.keras.metrics.Mean()\n",
    "        self.train_loss_2 = tf.keras.metrics.Mean()\n",
    "        \n",
    "        self.train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.train_accuracy_2 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "        \n",
    "        self.test_loss = tf.keras.metrics.Mean()\n",
    "        self.test_loss_2 = tf.keras.metrics.Mean()\n",
    "        self.test_loss_3 = tf.keras.metrics.Mean()\n",
    "        self.test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.test_accuracy_2 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.test_accuracy_3 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    @tf.function\n",
    "    def train_both(self, x_class, y_class, x_domain):\n",
    "        \n",
    "        domain_labels = np.concatenate([np.zeros(len(x_class)), np.ones(len(x_domain))])\n",
    "        \n",
    "        x_both = tf.concat([x_class, x_domain], axis = 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_class_pred = self.path_1(x_class)\n",
    "            loss_1 = self.loss(y_class, y_class_pred)   \n",
    "        grad_1 = tape.gradient(loss_1, self.path_1.trainable_variables)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_domain_pred = self.path_2(x_both)\n",
    "            loss_2 = self.loss_2(domain_labels, y_domain_pred) \n",
    "        grad_2 = tape.gradient(loss_2, self.path_2.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(grad_1, self.path_1.trainable_variables))\n",
    "        self.optimizer_2.apply_gradients(zip(grad_2, self.path_2.trainable_variables))\n",
    "        self.train_loss(loss_1)\n",
    "        self.train_accuracy(y_class, y_class_pred)\n",
    "        \n",
    "        self.train_loss_2(loss_2)\n",
    "        self.train_accuracy_2(domain_labels, y_domain_pred)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    @tf.function\n",
    "    def test_both(self, x_class, y_class, x_domain, y_domain):\n",
    "        \n",
    "        domain_labels = np.concatenate([np.zeros(len(x_class)), np.ones(len(x_domain))])\n",
    "        \n",
    "        x_both = tf.concat([x_class, x_domain], axis = 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_class_pred = self.path_1(x_class)\n",
    "            y_domain_pred = self.path_2(x_both)\n",
    "            y_target_class_pred = self.path_1(x_domain)\n",
    "            \n",
    "            loss_1 = self.loss(y_class, y_class_pred)\n",
    "            loss_2 = self.loss_2(domain_labels, y_domain_pred)\n",
    "            loss_3 = self.loss_3(y_domain, y_target_class_pred)\n",
    "            \n",
    "        self.test_loss(loss_1)\n",
    "        self.test_accuracy(y_class, y_class_pred)\n",
    "        \n",
    "        self.test_loss_2(loss_2)\n",
    "        self.test_accuracy_2(domain_labels, y_domain_pred)\n",
    "        \n",
    "        self.test_loss_3(loss_3)\n",
    "        self.test_accuracy_3(y_domain, y_target_class_pred)\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist = np.load('../data/mnist/x_train.npy')\n",
    "y_train_mnist = np.load('../data/mnist/y_train.npy')\n",
    "\n",
    "x_test_mnist = np.load('../data/mnist/x_test.npy')\n",
    "y_test_mnist = np.load('../data/mnist/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_svhn = np.load('../data/svhn/x_train.npy')\n",
    "y_train_svhn = np.load('../data/svhn/y_train.npy')\n",
    "\n",
    "x_test_svhn = np.load('../data/svhn/x_test.npy')\n",
    "y_test_svhn = np.load('../data/svhn/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
    "x_train_svhn, x_test_svhn = x_train_svhn / 255.0, x_test_svhn / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist = tf.cast(x_train_mnist, tf.float32)\n",
    "x_test_mnist = tf.cast(x_test_mnist, tf.float32)\n",
    "x_train_svhn = tf.cast(x_train_svhn, tf.float32)\n",
    "x_test_svhn = tf.cast(x_test_svhn, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(x, y):\n",
    "    \n",
    "    paddings = tf.constant([[2, 2,], [2, 2]])\n",
    "    \n",
    "    new_x = tf.pad(x, paddings, \"CONSTANT\")\n",
    "    \n",
    "    return (new_x, y)\n",
    "\n",
    "def duplicate_channel(x, y):\n",
    "\n",
    "    new_x = tf.stack([x, x, x], axis = -1)\n",
    "    \n",
    "    return (new_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([73257, 32, 32, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_svhn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([26032, 32, 32, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_svhn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = tf.data.Dataset.from_tensor_slices((x_train_mnist, y_train_mnist))\n",
    "mnist_train_dataset = mnist_train_dataset.map(pad_image)\n",
    "mnist_train_dataset = mnist_train_dataset.map(duplicate_channel)\n",
    "target_train_dataset = mnist_train_dataset.shuffle(len(y_train_mnist))\n",
    "\n",
    "mnist_test_dataset = tf.data.Dataset.from_tensor_slices((x_test_mnist, y_test_mnist))\n",
    "mnist_test_dataset = mnist_test_dataset.map(pad_image)\n",
    "mnist_test_dataset = mnist_test_dataset.map(duplicate_channel)\n",
    "target_test_dataset = mnist_test_dataset.shuffle(len(y_test_mnist))\n",
    "\n",
    "svhn_train_dataset = tf.data.Dataset.from_tensor_slices((x_train_svhn, y_train_svhn))\n",
    "source_train_dataset = svhn_train_dataset.shuffle(len(y_train_svhn))\n",
    "\n",
    "svhn_test_dataset = tf.data.Dataset.from_tensor_slices((x_test_svhn, y_test_svhn))\n",
    "source_test_dataset = svhn_train_dataset.shuffle(len(y_test_svhn))\n",
    "\n",
    "\n",
    "\n",
    "source_train_dataset = source_train_dataset.batch(730)\n",
    "source_train_dataset = source_train_dataset.prefetch(50)\n",
    "\n",
    "source_test_dataset = source_test_dataset.batch(260)\n",
    "source_test_dataset = source_test_dataset.prefetch(50)\n",
    "\n",
    "target_train_dataset = target_train_dataset.batch(600)\n",
    "target_train_dataset = target_train_dataset.prefetch(50)\n",
    "\n",
    "# target_test_dataset = target_test_dataset.batch(500)\n",
    "# target_test_dataset = target_test_dataset.prefetch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SVHN(input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0627 19:55:17.236991 19648 deprecation.py:323] From c:\\users\\jw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "L1: 2.2226, Acc1: 20.47, L1 Test: 1.9192, Acc1 Test: 31.99\n",
      "L2: 0.6650, Acc2: 65.76, L2 Test: 0.5417, Acc2 Test: 99.49\n",
      "L3 Test: 2.1667, Acc3 Test: 18.65\n",
      "\n",
      "Epoch: 2\n",
      "L1: 1.6695, Acc1: 41.79, L1 Test: 1.2615, Acc1 Test: 56.57\n",
      "L2: 0.6566, Acc2: 70.22, L2 Test: 0.3700, Acc2 Test: 98.04\n",
      "L3 Test: 2.6132, Acc3 Test: 32.98\n",
      "\n",
      "Epoch: 3\n",
      "L1: 1.2751, Acc1: 56.21, L1 Test: 0.9863, Acc1 Test: 66.54\n",
      "L2: 0.4785, Acc2: 79.10, L2 Test: 0.2922, Acc2 Test: 96.88\n",
      "L3 Test: 2.4809, Acc3 Test: 41.17\n",
      "\n",
      "Epoch: 4\n",
      "L1: 1.0527, Acc1: 64.22, L1 Test: 0.8234, Acc1 Test: 72.38\n",
      "L2: 0.5205, Acc2: 79.46, L2 Test: 0.2518, Acc2 Test: 96.41\n",
      "L3 Test: 2.5056, Acc3 Test: 44.31\n",
      "\n",
      "Epoch: 5\n",
      "L1: 0.9068, Acc1: 69.42, L1 Test: 0.7163, Acc1 Test: 76.16\n",
      "L2: 0.4413, Acc2: 82.79, L2 Test: 0.2257, Acc2 Test: 96.32\n",
      "L3 Test: 2.7590, Acc3 Test: 45.94\n",
      "\n",
      "Epoch: 6\n",
      "L1: 0.8020, Acc1: 73.13, L1 Test: 0.6402, Acc1 Test: 78.83\n",
      "L2: 0.3749, Acc2: 85.47, L2 Test: 0.1912, Acc2 Test: 96.85\n",
      "L3 Test: 2.6585, Acc3 Test: 47.88\n",
      "\n",
      "Epoch: 7\n",
      "L1: 0.7246, Acc1: 75.85, L1 Test: 0.5877, Acc1 Test: 80.67\n",
      "L2: 0.4195, Acc2: 84.96, L2 Test: 0.2576, Acc2 Test: 93.02\n",
      "L3 Test: 2.9148, Acc3 Test: 45.93\n",
      "\n",
      "Epoch: 8\n",
      "L1: 0.6621, Acc1: 78.04, L1 Test: 0.5415, Acc1 Test: 82.25\n",
      "L2: 0.3938, Acc2: 85.93, L2 Test: 0.2441, Acc2 Test: 93.16\n",
      "L3 Test: 2.9431, Acc3 Test: 46.64\n",
      "\n",
      "Epoch: 9\n",
      "L1: 0.6109, Acc1: 79.81, L1 Test: 0.5046, Acc1 Test: 83.51\n",
      "L2: 0.3540, Acc2: 87.39, L2 Test: 0.2190, Acc2 Test: 93.87\n",
      "L3 Test: 2.9350, Acc3 Test: 47.66\n",
      "\n",
      "Epoch: 10\n",
      "L1: 0.5676, Acc1: 81.30, L1 Test: 0.4730, Acc1 Test: 84.58\n",
      "L2: 0.3246, Acc2: 88.46, L2 Test: 0.1989, Acc2 Test: 94.43\n",
      "L3 Test: 2.9498, Acc3 Test: 48.45\n",
      "\n",
      "Epoch: 11\n",
      "L1: 0.5304, Acc1: 82.56, L1 Test: 0.4429, Acc1 Test: 85.58\n",
      "L2: 0.2966, Acc2: 89.47, L2 Test: 0.1815, Acc2 Test: 94.92\n",
      "L3 Test: 2.9875, Acc3 Test: 49.10\n",
      "\n",
      "Epoch: 12\n",
      "L1: 0.4976, Acc1: 83.66, L1 Test: 0.4174, Acc1 Test: 86.42\n",
      "L2: 0.2726, Acc2: 90.33, L2 Test: 0.1667, Acc2 Test: 95.33\n",
      "L3 Test: 3.0817, Acc3 Test: 49.56\n",
      "\n",
      "Epoch: 13\n",
      "L1: 0.4680, Acc1: 84.65, L1 Test: 0.3950, Acc1 Test: 87.16\n",
      "L2: 0.2520, Acc2: 91.06, L2 Test: 0.1541, Acc2 Test: 95.68\n",
      "L3 Test: 3.2312, Acc3 Test: 50.23\n",
      "\n",
      "Epoch: 14\n",
      "L1: 0.4416, Acc1: 85.53, L1 Test: 0.3763, Acc1 Test: 87.77\n",
      "L2: 0.2341, Acc2: 91.69, L2 Test: 0.1432, Acc2 Test: 95.99\n",
      "L3 Test: 3.4936, Acc3 Test: 50.50\n",
      "\n",
      "Epoch: 15\n",
      "L1: 0.4176, Acc1: 86.32, L1 Test: 0.3583, Acc1 Test: 88.35\n",
      "L2: 0.2186, Acc2: 92.25, L2 Test: 0.1338, Acc2 Test: 96.25\n",
      "L3 Test: 3.7112, Acc3 Test: 51.02\n",
      "\n",
      "Epoch: 16\n",
      "L1: 0.3959, Acc1: 87.03, L1 Test: 0.3418, Acc1 Test: 88.89\n",
      "L2: 0.2050, Acc2: 92.73, L2 Test: 0.1255, Acc2 Test: 96.48\n",
      "L3 Test: 3.8653, Acc3 Test: 51.54\n",
      "\n",
      "Epoch: 17\n",
      "L1: 0.3762, Acc1: 87.68, L1 Test: 0.3287, Acc1 Test: 89.33\n",
      "L2: 0.1930, Acc2: 93.16, L2 Test: 0.1181, Acc2 Test: 96.69\n",
      "L3 Test: 3.9835, Acc3 Test: 52.14\n",
      "\n",
      "Epoch: 18\n",
      "L1: 0.3584, Acc1: 88.26, L1 Test: 0.3164, Acc1 Test: 89.74\n",
      "L2: 0.1823, Acc2: 93.54, L2 Test: 0.1116, Acc2 Test: 96.87\n",
      "L3 Test: 4.1774, Acc3 Test: 52.41\n",
      "\n",
      "Epoch: 19\n",
      "L1: 0.3425, Acc1: 88.78, L1 Test: 0.3045, Acc1 Test: 90.12\n",
      "L2: 0.1727, Acc2: 93.87, L2 Test: 0.1057, Acc2 Test: 97.04\n",
      "L3 Test: 4.2878, Acc3 Test: 52.87\n",
      "\n",
      "Epoch: 20\n",
      "L1: 0.3276, Acc1: 89.27, L1 Test: 0.2934, Acc1 Test: 90.48\n",
      "L2: 0.1641, Acc2: 94.18, L2 Test: 0.1005, Acc2 Test: 97.19\n",
      "L3 Test: 4.4637, Acc3 Test: 53.09\n",
      "\n",
      "Epoch: 21\n",
      "L1: 0.3137, Acc1: 89.72, L1 Test: 0.2837, Acc1 Test: 90.81\n",
      "L2: 0.1563, Acc2: 94.46, L2 Test: 0.0957, Acc2 Test: 97.32\n",
      "L3 Test: 4.7240, Acc3 Test: 53.26\n",
      "\n",
      "Epoch: 22\n",
      "L1: 0.3013, Acc1: 90.13, L1 Test: 0.2747, Acc1 Test: 91.11\n",
      "L2: 0.1492, Acc2: 94.71, L2 Test: 0.0913, Acc2 Test: 97.44\n",
      "L3 Test: 4.8343, Acc3 Test: 53.57\n",
      "\n",
      "Epoch: 23\n",
      "L1: 0.2899, Acc1: 90.50, L1 Test: 0.2653, Acc1 Test: 91.42\n",
      "L2: 0.1428, Acc2: 94.94, L2 Test: 0.0874, Acc2 Test: 97.55\n",
      "L3 Test: 5.0110, Acc3 Test: 53.75\n",
      "\n",
      "Epoch: 24\n",
      "L1: 0.2790, Acc1: 90.86, L1 Test: 0.2566, Acc1 Test: 91.71\n",
      "L2: 0.1368, Acc2: 95.15, L2 Test: 0.0837, Acc2 Test: 97.65\n",
      "L3 Test: 5.1383, Acc3 Test: 54.02\n",
      "\n",
      "Epoch: 25\n",
      "L1: 0.2688, Acc1: 91.19, L1 Test: 0.2482, Acc1 Test: 91.98\n",
      "L2: 0.1313, Acc2: 95.34, L2 Test: 0.0804, Acc2 Test: 97.75\n",
      "L3 Test: 5.3547, Acc3 Test: 54.17\n",
      "\n",
      "Epoch: 26\n",
      "L1: 0.2596, Acc1: 91.49, L1 Test: 0.2403, Acc1 Test: 92.24\n",
      "L2: 0.1263, Acc2: 95.52, L2 Test: 0.0773, Acc2 Test: 97.83\n",
      "L3 Test: 5.5515, Acc3 Test: 54.22\n",
      "\n",
      "Epoch: 27\n",
      "L1: 0.2508, Acc1: 91.78, L1 Test: 0.2327, Acc1 Test: 92.49\n",
      "L2: 0.1217, Acc2: 95.69, L2 Test: 0.0745, Acc2 Test: 97.91\n",
      "L3 Test: 5.7617, Acc3 Test: 54.34\n",
      "\n",
      "Epoch: 28\n",
      "L1: 0.2426, Acc1: 92.06, L1 Test: 0.2260, Acc1 Test: 92.71\n",
      "L2: 0.1173, Acc2: 95.84, L2 Test: 0.0718, Acc2 Test: 97.99\n",
      "L3 Test: 5.9549, Acc3 Test: 54.49\n",
      "\n",
      "Epoch: 29\n",
      "L1: 0.2348, Acc1: 92.31, L1 Test: 0.2194, Acc1 Test: 92.93\n",
      "L2: 0.1133, Acc2: 95.98, L2 Test: 0.0693, Acc2 Test: 98.06\n",
      "L3 Test: 6.1481, Acc3 Test: 54.66\n",
      "\n",
      "Epoch: 30\n",
      "L1: 0.2274, Acc1: 92.55, L1 Test: 0.2126, Acc1 Test: 93.15\n",
      "L2: 0.1095, Acc2: 96.12, L2 Test: 0.0670, Acc2 Test: 98.12\n",
      "L3 Test: 6.2808, Acc3 Test: 54.95\n",
      "\n",
      "Epoch: 31\n",
      "L1: 0.2204, Acc1: 92.78, L1 Test: 0.2064, Acc1 Test: 93.35\n",
      "L2: 0.1060, Acc2: 96.24, L2 Test: 0.0649, Acc2 Test: 98.18\n",
      "L3 Test: 6.4678, Acc3 Test: 55.00\n",
      "\n",
      "Epoch: 32\n",
      "L1: 0.2139, Acc1: 93.00, L1 Test: 0.2010, Acc1 Test: 93.52\n",
      "L2: 0.1027, Acc2: 96.36, L2 Test: 0.0629, Acc2 Test: 98.24\n",
      "L3 Test: 6.6198, Acc3 Test: 55.03\n",
      "\n",
      "Epoch: 33\n",
      "L1: 0.2079, Acc1: 93.19, L1 Test: 0.1958, Acc1 Test: 93.69\n",
      "L2: 0.0996, Acc2: 96.47, L2 Test: 0.0610, Acc2 Test: 98.29\n",
      "L3 Test: 6.7342, Acc3 Test: 55.27\n",
      "\n",
      "Epoch: 34\n",
      "L1: 0.2021, Acc1: 93.38, L1 Test: 0.1908, Acc1 Test: 93.85\n",
      "L2: 0.0967, Acc2: 96.57, L2 Test: 0.0592, Acc2 Test: 98.34\n",
      "L3 Test: 6.8490, Acc3 Test: 55.38\n",
      "\n",
      "Epoch: 35\n",
      "L1: 0.1968, Acc1: 93.56, L1 Test: 0.1860, Acc1 Test: 94.01\n",
      "L2: 0.0939, Acc2: 96.67, L2 Test: 0.0576, Acc2 Test: 98.39\n",
      "L3 Test: 6.9416, Acc3 Test: 55.42\n",
      "\n",
      "Epoch: 36\n",
      "L1: 0.1918, Acc1: 93.73, L1 Test: 0.1815, Acc1 Test: 94.16\n",
      "L2: 0.0914, Acc2: 96.76, L2 Test: 0.0560, Acc2 Test: 98.43\n",
      "L3 Test: 6.9777, Acc3 Test: 55.60\n",
      "\n",
      "Epoch: 37\n",
      "L1: 0.1869, Acc1: 93.88, L1 Test: 0.1774, Acc1 Test: 94.29\n",
      "L2: 0.0889, Acc2: 96.85, L2 Test: 0.0545, Acc2 Test: 98.47\n",
      "L3 Test: 7.0848, Acc3 Test: 55.67\n",
      "\n",
      "Epoch: 38\n",
      "L1: 0.1824, Acc1: 94.03, L1 Test: 0.1733, Acc1 Test: 94.42\n",
      "L2: 0.0866, Acc2: 96.93, L2 Test: 0.0530, Acc2 Test: 98.51\n",
      "L3 Test: 7.1892, Acc3 Test: 55.75\n",
      "\n",
      "Epoch: 39\n",
      "L1: 0.1781, Acc1: 94.18, L1 Test: 0.1694, Acc1 Test: 94.55\n",
      "L2: 0.0843, Acc2: 97.01, L2 Test: 0.0517, Acc2 Test: 98.55\n",
      "L3 Test: 7.3358, Acc3 Test: 55.83\n",
      "\n",
      "Epoch: 40\n",
      "L1: 0.1739, Acc1: 94.31, L1 Test: 0.1657, Acc1 Test: 94.67\n",
      "L2: 0.0822, Acc2: 97.08, L2 Test: 0.0504, Acc2 Test: 98.59\n",
      "L3 Test: 7.3643, Acc3 Test: 55.97\n",
      "\n",
      "Epoch: 41\n",
      "L1: 0.1701, Acc1: 94.44, L1 Test: 0.1622, Acc1 Test: 94.79\n",
      "L2: 0.0802, Acc2: 97.16, L2 Test: 0.0492, Acc2 Test: 98.62\n",
      "L3 Test: 7.4280, Acc3 Test: 56.03\n",
      "\n",
      "Epoch: 42\n",
      "L1: 0.1663, Acc1: 94.56, L1 Test: 0.1591, Acc1 Test: 94.89\n",
      "L2: 0.0783, Acc2: 97.22, L2 Test: 0.0480, Acc2 Test: 98.65\n",
      "L3 Test: 7.4896, Acc3 Test: 56.16\n",
      "\n",
      "Epoch: 43\n",
      "L1: 0.1628, Acc1: 94.68, L1 Test: 0.1561, Acc1 Test: 94.99\n",
      "L2: 0.0765, Acc2: 97.29, L2 Test: 0.0469, Acc2 Test: 98.69\n",
      "L3 Test: 7.5906, Acc3 Test: 56.22\n",
      "\n",
      "Epoch: 44\n",
      "L1: 0.1592, Acc1: 94.80, L1 Test: 0.1529, Acc1 Test: 95.10\n",
      "L2: 0.0748, Acc2: 97.35, L2 Test: 0.0458, Acc2 Test: 98.72\n",
      "L3 Test: 7.6880, Acc3 Test: 56.29\n",
      "\n",
      "Epoch: 45\n",
      "L1: 0.1559, Acc1: 94.91, L1 Test: 0.1499, Acc1 Test: 95.19\n",
      "L2: 0.0731, Acc2: 97.41, L2 Test: 0.0448, Acc2 Test: 98.74\n",
      "L3 Test: 7.7827, Acc3 Test: 56.32\n",
      "\n",
      "Epoch: 46\n",
      "L1: 0.1528, Acc1: 95.01, L1 Test: 0.1473, Acc1 Test: 95.28\n",
      "L2: 0.0715, Acc2: 97.46, L2 Test: 0.0438, Acc2 Test: 98.77\n",
      "L3 Test: 7.9567, Acc3 Test: 56.27\n",
      "\n",
      "Epoch: 47\n",
      "L1: 0.1498, Acc1: 95.11, L1 Test: 0.1447, Acc1 Test: 95.37\n",
      "L2: 0.0700, Acc2: 97.52, L2 Test: 0.0429, Acc2 Test: 98.80\n",
      "L3 Test: 8.0625, Acc3 Test: 56.26\n",
      "\n",
      "Epoch: 48\n",
      "L1: 0.1470, Acc1: 95.20, L1 Test: 0.1421, Acc1 Test: 95.45\n",
      "L2: 0.0685, Acc2: 97.57, L2 Test: 0.0420, Acc2 Test: 98.82\n",
      "L3 Test: 8.1711, Acc3 Test: 56.22\n",
      "\n",
      "Epoch: 49\n",
      "L1: 0.1443, Acc1: 95.29, L1 Test: 0.1397, Acc1 Test: 95.53\n",
      "L2: 0.0671, Acc2: 97.62, L2 Test: 0.0411, Acc2 Test: 98.85\n",
      "L3 Test: 8.2231, Acc3 Test: 56.28\n",
      "\n",
      "Epoch: 50\n",
      "L1: 0.1417, Acc1: 95.38, L1 Test: 0.1374, Acc1 Test: 95.60\n",
      "L2: 0.0658, Acc2: 97.67, L2 Test: 0.0403, Acc2 Test: 98.87\n",
      "L3 Test: 8.3035, Acc3 Test: 56.34\n",
      "\n",
      "Epoch: 51\n",
      "L1: 0.1391, Acc1: 95.46, L1 Test: 0.1352, Acc1 Test: 95.67\n",
      "L2: 0.0645, Acc2: 97.71, L2 Test: 0.0395, Acc2 Test: 98.89\n",
      "L3 Test: 8.3383, Acc3 Test: 56.42\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52\n",
      "L1: 0.1367, Acc1: 95.54, L1 Test: 0.1331, Acc1 Test: 95.74\n",
      "L2: 0.0633, Acc2: 97.76, L2 Test: 0.0388, Acc2 Test: 98.91\n",
      "L3 Test: 8.4220, Acc3 Test: 56.42\n",
      "\n",
      "Epoch: 53\n",
      "L1: 0.1343, Acc1: 95.62, L1 Test: 0.1308, Acc1 Test: 95.81\n",
      "L2: 0.0621, Acc2: 97.80, L2 Test: 0.0380, Acc2 Test: 98.93\n",
      "L3 Test: 8.4547, Acc3 Test: 56.49\n",
      "\n",
      "Epoch: 54\n",
      "L1: 0.1320, Acc1: 95.69, L1 Test: 0.1288, Acc1 Test: 95.88\n",
      "L2: 0.0609, Acc2: 97.84, L2 Test: 0.0373, Acc2 Test: 98.95\n",
      "L3 Test: 8.5099, Acc3 Test: 56.53\n",
      "\n",
      "Epoch: 55\n",
      "L1: 0.1299, Acc1: 95.76, L1 Test: 0.1273, Acc1 Test: 95.93\n",
      "L2: 0.0598, Acc2: 97.88, L2 Test: 0.0367, Acc2 Test: 98.97\n",
      "L3 Test: 8.5275, Acc3 Test: 56.72\n",
      "\n",
      "Epoch: 56\n",
      "L1: 0.1278, Acc1: 95.83, L1 Test: 0.1252, Acc1 Test: 96.00\n",
      "L2: 0.0588, Acc2: 97.92, L2 Test: 0.0360, Acc2 Test: 98.99\n",
      "L3 Test: 8.5572, Acc3 Test: 56.80\n",
      "\n",
      "Epoch: 57\n",
      "L1: 0.1258, Acc1: 95.90, L1 Test: 0.1233, Acc1 Test: 96.06\n",
      "L2: 0.0577, Acc2: 97.95, L2 Test: 0.0354, Acc2 Test: 99.01\n",
      "L3 Test: 8.6032, Acc3 Test: 56.90\n",
      "\n",
      "Epoch: 58\n",
      "L1: 0.1238, Acc1: 95.97, L1 Test: 0.1215, Acc1 Test: 96.12\n",
      "L2: 0.0567, Acc2: 97.99, L2 Test: 0.0348, Acc2 Test: 99.03\n",
      "L3 Test: 8.6208, Acc3 Test: 57.03\n",
      "\n",
      "Epoch: 59\n",
      "L1: 0.1219, Acc1: 96.03, L1 Test: 0.1198, Acc1 Test: 96.18\n",
      "L2: 0.0558, Acc2: 98.02, L2 Test: 0.0342, Acc2 Test: 99.04\n",
      "L3 Test: 8.6505, Acc3 Test: 57.08\n",
      "\n",
      "Epoch: 60\n",
      "L1: 0.1200, Acc1: 96.09, L1 Test: 0.1179, Acc1 Test: 96.24\n",
      "L2: 0.0548, Acc2: 98.06, L2 Test: 0.0336, Acc2 Test: 99.06\n",
      "L3 Test: 8.6900, Acc3 Test: 57.14\n",
      "\n",
      "Epoch: 61\n",
      "L1: 0.1182, Acc1: 96.15, L1 Test: 0.1164, Acc1 Test: 96.29\n",
      "L2: 0.0540, Acc2: 98.09, L2 Test: 0.0331, Acc2 Test: 99.07\n",
      "L3 Test: 8.7594, Acc3 Test: 57.21\n",
      "\n",
      "Epoch: 62\n",
      "L1: 0.1165, Acc1: 96.21, L1 Test: 0.1149, Acc1 Test: 96.34\n",
      "L2: 0.0531, Acc2: 98.12, L2 Test: 0.0325, Acc2 Test: 99.09\n",
      "L3 Test: 8.8018, Acc3 Test: 57.29\n",
      "\n",
      "Epoch: 63\n",
      "L1: 0.1149, Acc1: 96.26, L1 Test: 0.1133, Acc1 Test: 96.39\n",
      "L2: 0.0522, Acc2: 98.15, L2 Test: 0.0320, Acc2 Test: 99.10\n",
      "L3 Test: 8.8885, Acc3 Test: 57.31\n",
      "\n",
      "Epoch: 64\n",
      "L1: 0.1132, Acc1: 96.32, L1 Test: 0.1118, Acc1 Test: 96.44\n",
      "L2: 0.0514, Acc2: 98.18, L2 Test: 0.0315, Acc2 Test: 99.12\n",
      "L3 Test: 8.9633, Acc3 Test: 57.35\n",
      "\n",
      "Epoch: 65\n",
      "L1: 0.1117, Acc1: 96.37, L1 Test: 0.1103, Acc1 Test: 96.49\n",
      "L2: 0.0506, Acc2: 98.20, L2 Test: 0.0311, Acc2 Test: 99.13\n",
      "L3 Test: 9.0719, Acc3 Test: 57.32\n",
      "\n",
      "Epoch: 66\n",
      "L1: 0.1102, Acc1: 96.42, L1 Test: 0.1089, Acc1 Test: 96.54\n",
      "L2: 0.0499, Acc2: 98.23, L2 Test: 0.0306, Acc2 Test: 99.14\n",
      "L3 Test: 9.1478, Acc3 Test: 57.36\n",
      "\n",
      "Epoch: 67\n",
      "L1: 0.1087, Acc1: 96.47, L1 Test: 0.1075, Acc1 Test: 96.59\n",
      "L2: 0.0491, Acc2: 98.26, L2 Test: 0.0302, Acc2 Test: 99.15\n",
      "L3 Test: 9.2386, Acc3 Test: 57.44\n",
      "\n",
      "Epoch: 68\n",
      "L1: 0.1072, Acc1: 96.51, L1 Test: 0.1061, Acc1 Test: 96.63\n",
      "L2: 0.0484, Acc2: 98.28, L2 Test: 0.0297, Acc2 Test: 99.17\n",
      "L3 Test: 9.3084, Acc3 Test: 57.51\n",
      "\n",
      "Epoch: 69\n",
      "L1: 0.1058, Acc1: 96.56, L1 Test: 0.1048, Acc1 Test: 96.68\n",
      "L2: 0.0477, Acc2: 98.31, L2 Test: 0.0293, Acc2 Test: 99.18\n",
      "L3 Test: 9.3701, Acc3 Test: 57.55\n",
      "\n",
      "Epoch: 70\n",
      "L1: 0.1044, Acc1: 96.60, L1 Test: 0.1035, Acc1 Test: 96.72\n",
      "L2: 0.0470, Acc2: 98.33, L2 Test: 0.0289, Acc2 Test: 99.19\n",
      "L3 Test: 9.4373, Acc3 Test: 57.57\n",
      "\n",
      "Epoch: 71\n",
      "L1: 0.1031, Acc1: 96.65, L1 Test: 0.1023, Acc1 Test: 96.76\n",
      "L2: 0.0464, Acc2: 98.36, L2 Test: 0.0285, Acc2 Test: 99.20\n",
      "L3 Test: 9.5363, Acc3 Test: 57.60\n",
      "\n",
      "Epoch: 72\n",
      "L1: 0.1018, Acc1: 96.69, L1 Test: 0.1011, Acc1 Test: 96.80\n",
      "L2: 0.0457, Acc2: 98.38, L2 Test: 0.0281, Acc2 Test: 99.21\n",
      "L3 Test: 9.5985, Acc3 Test: 57.69\n",
      "\n",
      "Epoch: 73\n",
      "L1: 0.1006, Acc1: 96.73, L1 Test: 0.0999, Acc1 Test: 96.84\n",
      "L2: 0.0451, Acc2: 98.40, L2 Test: 0.0277, Acc2 Test: 99.22\n",
      "L3 Test: 9.6669, Acc3 Test: 57.69\n",
      "\n",
      "Epoch: 74\n",
      "L1: 0.0993, Acc1: 96.77, L1 Test: 0.0987, Acc1 Test: 96.87\n",
      "L2: 0.0445, Acc2: 98.42, L2 Test: 0.0274, Acc2 Test: 99.23\n",
      "L3 Test: 9.7284, Acc3 Test: 57.75\n",
      "\n",
      "Epoch: 75\n",
      "L1: 0.0981, Acc1: 96.81, L1 Test: 0.0976, Acc1 Test: 96.91\n",
      "L2: 0.0440, Acc2: 98.44, L2 Test: 0.0270, Acc2 Test: 99.24\n",
      "L3 Test: 9.7935, Acc3 Test: 57.81\n",
      "\n",
      "Epoch: 76\n",
      "L1: 0.0969, Acc1: 96.85, L1 Test: 0.0964, Acc1 Test: 96.95\n",
      "L2: 0.0434, Acc2: 98.46, L2 Test: 0.0267, Acc2 Test: 99.25\n",
      "L3 Test: 9.8602, Acc3 Test: 57.86\n",
      "\n",
      "Epoch: 77\n",
      "L1: 0.0958, Acc1: 96.89, L1 Test: 0.0954, Acc1 Test: 96.98\n",
      "L2: 0.0429, Acc2: 98.48, L2 Test: 0.0263, Acc2 Test: 99.26\n",
      "L3 Test: 9.9278, Acc3 Test: 57.92\n",
      "\n",
      "Epoch: 78\n",
      "L1: 0.0947, Acc1: 96.92, L1 Test: 0.0944, Acc1 Test: 97.01\n",
      "L2: 0.0423, Acc2: 98.50, L2 Test: 0.0260, Acc2 Test: 99.27\n",
      "L3 Test: 9.9510, Acc3 Test: 57.99\n",
      "\n",
      "Epoch: 79\n",
      "L1: 0.0936, Acc1: 96.96, L1 Test: 0.0934, Acc1 Test: 97.05\n",
      "L2: 0.0418, Acc2: 98.52, L2 Test: 0.0257, Acc2 Test: 99.28\n",
      "L3 Test: 10.0026, Acc3 Test: 58.04\n",
      "\n",
      "Epoch: 80\n",
      "L1: 0.0925, Acc1: 97.00, L1 Test: 0.0923, Acc1 Test: 97.08\n",
      "L2: 0.0413, Acc2: 98.54, L2 Test: 0.0253, Acc2 Test: 99.29\n",
      "L3 Test: 10.1251, Acc3 Test: 58.06\n",
      "\n",
      "Epoch: 81\n",
      "L1: 0.0915, Acc1: 97.03, L1 Test: 0.0913, Acc1 Test: 97.12\n",
      "L2: 0.0408, Acc2: 98.56, L2 Test: 0.0250, Acc2 Test: 99.30\n",
      "L3 Test: 10.2022, Acc3 Test: 58.09\n",
      "\n",
      "Epoch: 82\n",
      "L1: 0.0905, Acc1: 97.06, L1 Test: 0.0903, Acc1 Test: 97.15\n",
      "L2: 0.0403, Acc2: 98.57, L2 Test: 0.0247, Acc2 Test: 99.31\n",
      "L3 Test: 10.2841, Acc3 Test: 58.13\n",
      "\n",
      "Epoch: 83\n",
      "L1: 0.0894, Acc1: 97.10, L1 Test: 0.0894, Acc1 Test: 97.18\n",
      "L2: 0.0398, Acc2: 98.59, L2 Test: 0.0244, Acc2 Test: 99.32\n",
      "L3 Test: 10.3512, Acc3 Test: 58.18\n",
      "\n",
      "Epoch: 84\n",
      "L1: 0.0885, Acc1: 97.13, L1 Test: 0.0884, Acc1 Test: 97.21\n",
      "L2: 0.0393, Acc2: 98.61, L2 Test: 0.0241, Acc2 Test: 99.32\n",
      "L3 Test: 10.4010, Acc3 Test: 58.25\n",
      "\n",
      "Epoch: 85\n",
      "L1: 0.0875, Acc1: 97.16, L1 Test: 0.0876, Acc1 Test: 97.24\n",
      "L2: 0.0388, Acc2: 98.62, L2 Test: 0.0239, Acc2 Test: 99.33\n",
      "L3 Test: 10.4511, Acc3 Test: 58.32\n",
      "\n",
      "Epoch: 86\n",
      "L1: 0.0866, Acc1: 97.19, L1 Test: 0.0867, Acc1 Test: 97.27\n",
      "L2: 0.0384, Acc2: 98.64, L2 Test: 0.0236, Acc2 Test: 99.34\n",
      "L3 Test: 10.5016, Acc3 Test: 58.42\n",
      "\n",
      "Epoch: 87\n",
      "L1: 0.0857, Acc1: 97.22, L1 Test: 0.0858, Acc1 Test: 97.30\n",
      "L2: 0.0380, Acc2: 98.65, L2 Test: 0.0233, Acc2 Test: 99.35\n",
      "L3 Test: 10.5745, Acc3 Test: 58.46\n",
      "\n",
      "Epoch: 88\n",
      "L1: 0.0848, Acc1: 97.25, L1 Test: 0.0849, Acc1 Test: 97.33\n",
      "L2: 0.0375, Acc2: 98.67, L2 Test: 0.0230, Acc2 Test: 99.35\n",
      "L3 Test: 10.6570, Acc3 Test: 58.50\n",
      "\n",
      "Epoch: 89\n",
      "L1: 0.0839, Acc1: 97.28, L1 Test: 0.0841, Acc1 Test: 97.35\n",
      "L2: 0.0371, Acc2: 98.68, L2 Test: 0.0228, Acc2 Test: 99.36\n",
      "L3 Test: 10.7017, Acc3 Test: 58.53\n",
      "\n",
      "Epoch: 90\n",
      "L1: 0.0831, Acc1: 97.31, L1 Test: 0.0833, Acc1 Test: 97.38\n",
      "L2: 0.0367, Acc2: 98.70, L2 Test: 0.0225, Acc2 Test: 99.37\n",
      "L3 Test: 10.8069, Acc3 Test: 58.55\n",
      "\n",
      "Epoch: 91\n",
      "L1: 0.0823, Acc1: 97.33, L1 Test: 0.0827, Acc1 Test: 97.40\n",
      "L2: 0.0363, Acc2: 98.71, L2 Test: 0.0223, Acc2 Test: 99.38\n",
      "L3 Test: 10.8729, Acc3 Test: 58.56\n",
      "\n",
      "Epoch: 92\n",
      "L1: 0.0815, Acc1: 97.36, L1 Test: 0.0820, Acc1 Test: 97.42\n",
      "L2: 0.0359, Acc2: 98.73, L2 Test: 0.0221, Acc2 Test: 99.38\n",
      "L3 Test: 10.9453, Acc3 Test: 58.58\n",
      "\n",
      "Epoch: 93\n",
      "L1: 0.0808, Acc1: 97.38, L1 Test: 0.0813, Acc1 Test: 97.45\n",
      "L2: 0.0355, Acc2: 98.74, L2 Test: 0.0218, Acc2 Test: 99.39\n",
      "L3 Test: 10.9928, Acc3 Test: 58.62\n",
      "\n",
      "Epoch: 94\n",
      "L1: 0.0800, Acc1: 97.41, L1 Test: 0.0806, Acc1 Test: 97.47\n",
      "L2: 0.0352, Acc2: 98.75, L2 Test: 0.0216, Acc2 Test: 99.39\n",
      "L3 Test: 11.0413, Acc3 Test: 58.57\n",
      "\n",
      "Epoch: 95\n",
      "L1: 0.0792, Acc1: 97.44, L1 Test: 0.0798, Acc1 Test: 97.50\n",
      "L2: 0.0349, Acc2: 98.77, L2 Test: 0.0214, Acc2 Test: 99.40\n",
      "L3 Test: 11.1051, Acc3 Test: 58.62\n",
      "\n",
      "Epoch: 96\n",
      "L1: 0.0785, Acc1: 97.46, L1 Test: 0.0792, Acc1 Test: 97.52\n",
      "L2: 0.0345, Acc2: 98.78, L2 Test: 0.0212, Acc2 Test: 99.41\n",
      "L3 Test: 11.1323, Acc3 Test: 58.68\n",
      "\n",
      "Epoch: 97\n",
      "L1: 0.0777, Acc1: 97.49, L1 Test: 0.0785, Acc1 Test: 97.54\n",
      "L2: 0.0341, Acc2: 98.79, L2 Test: 0.0209, Acc2 Test: 99.41\n",
      "L3 Test: 11.1694, Acc3 Test: 58.71\n",
      "\n",
      "Epoch: 98\n",
      "L1: 0.0770, Acc1: 97.51, L1 Test: 0.0778, Acc1 Test: 97.56\n",
      "L2: 0.0338, Acc2: 98.80, L2 Test: 0.0207, Acc2 Test: 99.42\n",
      "L3 Test: 11.2101, Acc3 Test: 58.75\n",
      "\n",
      "Epoch: 99\n",
      "L1: 0.0763, Acc1: 97.53, L1 Test: 0.0771, Acc1 Test: 97.59\n",
      "L2: 0.0335, Acc2: 98.81, L2 Test: 0.0205, Acc2 Test: 99.42\n",
      "L3 Test: 11.2451, Acc3 Test: 58.79\n",
      "\n",
      "Epoch: 100\n",
      "L1: 0.0756, Acc1: 97.56, L1 Test: 0.0764, Acc1 Test: 97.61\n",
      "L2: 0.0331, Acc2: 98.83, L2 Test: 0.0203, Acc2 Test: 99.43\n",
      "L3 Test: 11.3365, Acc3 Test: 58.78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (source_images, class_labels), (target_images, _) in zip(source_train_dataset, target_train_dataset):\n",
    "        model.train_both(source_images, class_labels, target_images)\n",
    "\n",
    "    for (test_images, test_labels), (target_images, target_labels) in zip(source_test_dataset, target_train_dataset):\n",
    "        model.test_both(test_images, test_labels, target_images, target_labels)\n",
    "\n",
    "    template = 'Epoch: {}\\n' + \\\n",
    "    'L1: {:.4f}, Acc1: {:.2f}, L1 Test: {:.4f}, Acc1 Test: {:.2f}\\n'+ \\\n",
    "    'L2: {:.4f}, Acc2: {:.2f}, L2 Test: {:.4f}, Acc2 Test: {:.2f}\\n'+ \\\n",
    "    'L3 Test: {:.4f}, Acc3 Test: {:.2f}\\n'\n",
    "    \n",
    "    \n",
    "    print(template.format(epoch+1,\n",
    "                         model.train_loss.result(),\n",
    "                         model.train_accuracy.result()*100,\n",
    "                         model.test_loss.result(),\n",
    "                         model.test_accuracy.result()*100,\n",
    "                         model.train_loss_2.result(),\n",
    "                         model.train_accuracy_2.result()*100,\n",
    "                         model.test_loss_2.result(),\n",
    "                         model.test_accuracy_2.result()*100,\n",
    "                         model.test_loss_3.result(),\n",
    "                         model.test_accuracy_3.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
